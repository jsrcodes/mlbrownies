
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">(</span>
    <span class="n">filters</span><span class="o">=</span><span class="s">''</span><span class="p">,</span>
    <span class="n">oov_token</span><span class="o">=</span><span class="s">'&lt;oov&gt;'</span>
<span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">tokenized_tensor</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">text_to_sequences</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Apply padding so that all sequences are of same length.
#The length of the largest string is considered for padding
</span><span class="n">tokenized_tensor</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">sequence</span><span class="p">.</span><span class="n">pad_sequences</span><span class="p">(</span>
    <span class="n">tensor</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'post'</span>
<span class="p">)</span>

</code></pre></div></div>
